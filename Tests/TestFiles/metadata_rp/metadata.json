{"113017.pdf": {"title": "RoSELS: Road Surface Extraction for 3D Automotive LiDAR Point Cloud Sequence", "author": "Dhvani Katkoria,Jaya Sreevalsan-Nair", "publisher": "SCITEPRESS - Science and Technology Publications", "date": "14-07-2022", "doi": "10.5220/0011301700003277", "keywords": "", "abstract": "Abstract: Road surface geometry provides information about navigable space in autonomous driving. Ground plane estimation is done on road points after semantic segmentation of three-dimensional (3D) automotive Li- DAR point clouds as a precursor to this geometry extraction. However, the actual geometry extraction is less explored, as it is expensive to use all road points for mesh generation. Thus, we propose a coarser surface approximation using road edge points. The geometry extraction for the entire sequence of a trajectory provides the complete road geometry, from the point of view of the ego-vehicle. Thus, we propose an automated system, RoSELS (Road Surface Extraction for LiDAR point cloud Sequence). Our novel approach involves ground point detection and road geometry classication, i.e. frame classication, for determining the road edge points. We use appropriate supervised and pre-trained transfer learning models, along with computational geometry algorithms to implement the workow. Our results on SemanticKITTI show that our extracted road surface for the sequence is qualitatively and quantitatively close to the reference trajectory."}, "2410.18402v1.Low_Rank_Tensor_Learning_by_Generalized_Nonconvex_Regularization.pdf": {"title": "Low-Rank Tensor Learning by Generalized Nonconvex Regularization", "author": "Sijia Xia,Michael K. Ng,Xiongjun Zhang", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18402", "keywords": "Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "In this paper, we study the problem of low-rank tensor learning, where only a few of training samples are observed and the underlying tensor has a low-rank structure. The existing methods are based on the sum of nuclear norms of unfolding matrices of a tensor, which may be suboptimal. In order to explore the low-rankness of the underlying tensor effectively, we propose a nonconvex model based on transformed tensor nuclear norm for low-rank tensor learning. Specifically, a family of nonconvex functions are employed onto the singular values of all frontal slices of a tensor in the transformed domain to characterize the low-rankness of the underlying tensor. An error bound between the stationary point of the nonconvex model and the underlying tensor is established under restricted strong convexity on the loss function (such as least squares loss and logistic regression) and suitable regularity conditions on the nonconvex penalty function. By reformulating the nonconvex function into the difference of two convex functions, a proximal majorization-minimization (PMM) algorithm is designed to solve the resulting model. Then the global convergence and convergence rate of PMM are established under very mild conditions. Numerical experiments are conducted on tensor completion and binary classification to demonstrate the effectiveness of the proposed method over other state-of-the-art methods."}, "2410.18404v1.Enhancing_Feature_Specific_Data_Protection_via_Bayesian_Coordinate_Differential_Privacy.pdf": {"title": "Enhancing Feature-Specific Data Protection via Bayesian Coordinate Differential Privacy", "author": "Maryam Aliakbarpour,Syomantak Chaudhuri,Thomas A. Courtade,Alireza Fallah,Michael I. Jordan", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18404", "keywords": "Machine Learning (cs.LG),Cryptography and Security (cs.CR),Machine Learning (stat.ML),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "Local Differential Privacy (LDP) offers strong privacy guarantees without requiring users to trust external parties. However, LDP applies uniform protection to all data features, including less sensitive ones, which degrades performance of downstream tasks. To overcome this limitation, we propose a Bayesian framework, Bayesian Coordinate Differential Privacy (BCDP), that enables feature-specific privacy quantification. This more nuanced approach complements LDP by adjusting privacy protection according to the sensitivity of each feature, enabling improved performance of downstream tasks without compromising privacy. We characterize the properties of BCDP and articulate its connections with standard non-Bayesian privacy frameworks. We further apply our BCDP framework to the problems of private mean estimation and ordinary least-squares regression. The BCDP-based approach obtains improved accuracy compared to a purely LDP-based approach, without compromising on privacy."}, "2410.18407v1.On_topological_solutions_to_a_generalized_Chern_Simons_equation_on_lattice_graphs.pdf": {"title": "On topological solutions to a generalized Chern-Simons equation on lattice graphs", "author": "Songbo Hou,Xiaoqing Kong", "publisher": "arXiv", "date": "24-10-2024", "doi": "10.48550/ARXIV.2410.18407", "keywords": "Analysis of PDEs (math.AP),Functional Analysis (math.FA),FOS: Mathematics,FOS: Mathematics,35A01 35A16 35J91 35R02", "abstract": "In this paper, we study a generalized self-dual Chern-Simons equation on the lattice graph $\\mathbb{Z}^n$ for $n \\geq 2$ as given by\n \\[\n \u0394u = \u03bbe^u (e^u - 1)^{2p+1} + 4\u03c0\\sum_{j=1}^M n_j \u03b4_{p_j},\n \\]\n where $\u0394$ denotes the Laplacian operator, $\u03bb$ is a positive constant, $p$ is a non-negative integer, $n_1, \\ldots, n_M$ are positive integers, and $p_1, \\ldots, p_M$ are distinct points with $\u03b4_{p_j}$ representing the Dirac delta function at $p_j$. We establish the existence of a topological solution that is maximal among all possible solutions. Our findings extend those of of Hua et al. [arXiv:2310.13905], Chao and Hou [J. Math. Anal. Appl. $\\bf{519}$(1), 126787(2023)], and Hou and Qiao [J. Math. Phys. $\\bf{65}$(8), 081503(2024)]."}, "2410.18410v1.FreCaS__Efficient_Higher_Resolution_Image_Generation_via_Frequency_aware_Cascaded_Sampling.pdf": {"title": "FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling", "author": "Zhengqiang Zhang,Ruihuang Li,Lei Zhang", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18410", "keywords": "Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "While image generation with diffusion models has achieved a great success, generating images of higher resolution than the training size remains a challenging task due to the high computational cost. Current methods typically perform the entire sampling process at full resolution and process all frequency components simultaneously, contradicting with the inherent coarse-to-fine nature of latent diffusion models and wasting computations on processing premature high-frequency details at early diffusion stages. To address this issue, we introduce an efficient $\\textbf{Fre}$quency-aware $\\textbf{Ca}$scaded $\\textbf{S}$ampling framework, $\\textbf{FreCaS}$ in short, for higher-resolution image generation. FreCaS decomposes the sampling process into cascaded stages with gradually increased resolutions, progressively expanding frequency bands and refining the corresponding details. We propose an innovative frequency-aware classifier-free guidance (FA-CFG) strategy to assign different guidance strengths for different frequency components, directing the diffusion model to add new details in the expanded frequency domain of each stage. Additionally, we fuse the cross-attention maps of previous and current stages to avoid synthesizing unfaithful layouts. Experiments demonstrate that FreCaS significantly outperforms state-of-the-art methods in image quality and generation speed. In particular, FreCaS is about 2.86$\\times$ and 6.07$\\times$ faster than ScaleCrafter and DemoFusion in generating a 2048$\\times$2048 image using a pre-trained SDXL model and achieves an FID$_b$ improvement of 11.6 and 3.7, respectively. FreCaS can be easily extended to more complex models such as SD3. The source code of FreCaS can be found at $\\href{\\text{https://github.com/xtudbxk/FreCaS}}{https://github.com/xtudbxk/FreCaS}$."}, "2410.18412v1.HardRace__A_Dynamic_Data_Race_Monitor_for_Production_Use.pdf": {"title": "HardRace: A Dynamic Data Race Monitor for Production Use", "author": "Xudong Sun,Zhuo Chen,Jingyang Shi,Yiyu Zhang,Peng Di,Xuandong Li,Zhiqiang Zuo", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18412", "keywords": "Software Engineering (cs.SE),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "Data races are critical issues in multithreaded program, leading to unpredictable, catastrophic and difficult-to-diagnose problems. Despite the extensive in-house testing, data races often escape to deployed software and manifest in production runs. Existing approaches suffer from either prohibitively high runtime overhead or incomplete detection capability. In this paper, we introduce HardRace, a data race monitor to detect races on-the-fly while with sufficiently low runtime overhead and high detection capability. HardRace firstly employs sound static analysis to determine a minimal set of essential memory accesses relevant to data races. It then leverages hardware trace instruction, i.e., Intel PTWRITE, to selectively record only these memory accesses and thread synchronization events during execution with negligible runtime overhead. Given the tracing data, HardRace performs standard data race detection algorithms to timely report potential races occurred in production runs. The experimental evaluations show that HardRace outperforms state-of-the-art tools like ProRace and Kard in terms of both runtime overhead and detection capability -- HardRace can detect all kinds of data races in read-world applications while maintaining a negligible overhead, less than 2% on average."}, "2410.18416v1.SkiLD__Unsupervised_Skill_Discovery_Guided_by_Factor_Interactions.pdf": {"title": "SkiLD: Unsupervised Skill Discovery Guided by Factor Interactions", "author": "Zizhao Wang,Jiaheng Hu,Caleb Chuck,Stephen Chen,Roberto Mart\u00edn-Mart\u00edn,Amy Zhang,Scott Niekum,Peter Stone", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18416", "keywords": "Machine Learning (cs.LG),Robotics (cs.RO),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "Unsupervised skill discovery carries the promise that an intelligent agent can learn reusable skills through autonomous, reward-free environment interaction. Existing unsupervised skill discovery methods learn skills by encouraging distinguishable behaviors that cover diverse states. However, in complex environments with many state factors (e.g., household environments with many objects), learning skills that cover all possible states is impossible, and naively encouraging state diversity often leads to simple skills that are not ideal for solving downstream tasks. This work introduces Skill Discovery from Local Dependencies (Skild), which leverages state factorization as a natural inductive bias to guide the skill learning process. The key intuition guiding Skild is that skills that induce <b>diverse interactions</b> between state factors are often more valuable for solving downstream tasks. To this end, Skild develops a novel skill learning objective that explicitly encourages the mastering of skills that effectively induce different interactions within an environment. We evaluate Skild in several domains with challenging, long-horizon sparse reward tasks including a realistic simulated household robot domain, where Skild successfully learns skills with clear semantic meaning and shows superior performance compared to existing unsupervised reinforcement learning methods that only maximize state coverage."}, "2410.18421v1.Atomistic_understanding_of_hydrogen_coverage_on_RuO2_110__surface_under_electrochemical_conditions_from_ab_initio_statistical_thermodynamics.pdf": {"title": "Atomistic understanding of hydrogen coverage on RuO2(110) surface under electrochemical conditions from ab initio statistical thermodynamics", "author": "Lei Zhang,Jan Kloppenburg,Chia-Yi Lin,Luka Mitrovic,Simon Gelin,Ismaila Dabo,Darrell G. Schlom,Jin Suntivich,Geoffroy Hautier", "publisher": "arXiv", "date": "24-10-2024", "doi": "10.48550/ARXIV.2410.18421", "keywords": "Materials Science (cond-mat.mtrl-sci),Chemical Physics (physics.chem-ph),FOS: Physical sciences,FOS: Physical sciences", "abstract": "Understanding the dehydrogenation of transition metal oxide surfaces under electrochemical potential is critical to the control of important chemical processes such as the oxygen evolution reaction (OER). Using first principles computations, we model the thermodynamic dehydrogenation process on RuO$_2$(110) and compare the results to experimental cyclic voltammetry (CV) on single crystal. We use a cluster expansion model trained on *ab initio* energy data coupled with Monte Carlo (MC) sampling to derive the macroscopic electrochemical observables, i.e., experimental CV, from the energetics of different hydrogen coverage microstates on well-defined RuO$_2$(110). Our model reproduces the unique \"two-peaks\" cyclic voltammogram observed experimentally with current density peak positions and shapes in good qualitative agreement. We show that RuO$_2$(110) starts as a water-covered surface with hydrogen on bridge (BRG) and coordination-unsaturated sites (CUS) at low potential (less than 0.4 V vs. reversible hydrogen electrode, RHE). As the potential increases, the hydrogens on BRG desorb, becoming the main contributor to the first CV peak with smaller contributions from CUS. When all BRG hydrogens are desorbed (before 1.2 V vs. RHE), the remaining CUS hydrogens desorb abruptly in a very small potential window leading to the sharp second peak observed during CV. Our work shows that above 1.23 V, the OER proceeds on a fully dehydrogenated RuO$_2$(110) surface."}, "2410.18424v1.A_Causal_Graph_Enhanced_Gaussian_Process_Regression_for_Modeling_Engine_out_NOx.pdf": {"title": "A Causal Graph-Enhanced Gaussian Process Regression for Modeling Engine-out NOx", "author": "Shrenik Zinage,Ilias Bilionis,Peter Meckl", "publisher": "arXiv", "date": "25-10-2024", "doi": "10.48550/ARXIV.2410.18424", "keywords": "Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "The stringent regulatory requirements on nitrogen oxides (NOx) emissions from diesel compression ignition engines require accurate and reliable models for real-time monitoring and diagnostics. Although traditional methods such as physical sensors and virtual engine control module (ECM) sensors provide essential data, they are only used for estimation. Ubiquitous literature primarily focuses on deterministic models with little emphasis on capturing the uncertainties due to sensors. The lack of probabilistic frameworks restricts the applicability of these models for robust diagnostics. The objective of this paper is to develop and validate a probabilistic model to predict engine-out NOx emissions using Gaussian process regression. Our approach is as follows. We employ three variants of Gaussian process models: the first with a standard radial basis function kernel with input window, the second incorporating a deep kernel using convolutional neural networks to capture temporal dependencies, and the third enriching the deep kernel with a causal graph derived via graph convolutional networks. The causal graph embeds physics knowledge into the learning process. All models are compared against a virtual ECM sensor using both quantitative and qualitative metrics. We conclude that our model provides an improvement in predictive performance when using an input window and a deep kernel structure. Even more compelling is the further enhancement achieved by the incorporation of a causal graph into the deep kernel. These findings are corroborated across different validation datasets."}, "2410.18443v1.ELECTRE_TRI_nB__pseudo_disjunctive__axiomatic_and_combinatorial_results.pdf": {"title": "ELECTRE TRI-nB, pseudo-disjunctive: axiomatic and combinatorial results", "author": "Denis Bouyssou,Thierry Marchant,Marc Pirlot", "publisher": "arXiv", "date": "24-10-2024", "doi": "10.48550/ARXIV.2410.18443", "keywords": "Discrete Mathematics (cs.DM),FOS: Computer and information sciences,FOS: Computer and information sciences", "abstract": "ELECTRE TRI-nB is a method designed to sort alternatives evaluated on several attributes into ordered categories. It is an extension of ELECTRE TRI-B, using several limiting profiles, instead of just one, to delimit each category. ELECTRE TRI-nB comes in two flavours: pseudo-conjunctive and pseudo-disjunctive. In a previous paper we have characterized the ordered partitions that can be obtained with ELECTRE TRI-nB, pseudo-conjunctive, using a simple axiom called linearity. The present paper is dedicated to the axiomatic analysis of ELECTRE TRI-nB, pseudo-disjunctive. It also provides some combinatorial results."}, "2410.18453v1.Density_of_states_of_the_Hubbard_model_supplemented_with_the_quantizing_magnetic_field.pdf": {"title": "Density of states of the Hubbard model supplemented with the quantizing magnetic field", "author": "Alexei Sherman", "publisher": "arXiv", "date": "24-10-2024", "doi": "10.48550/ARXIV.2410.18453", "keywords": "Strongly Correlated Electrons (cond-mat.str-el),FOS: Physical sciences,FOS: Physical sciences", "abstract": "Using the strong coupling diagram technique, we calculate the zero-temperature density of states $\u03c1$ of electrons on a square lattice immersed in a perpendicular uniform magnetic field. The electrons are described by Hubbard Hamiltonian. For moderate doping, Landau subbands are observed for small Hubbard repulsions $U$ only. For larger $U$, the subbands are blurred. Instead, small peaks varying with the field induction $B$ arise by opening the Mott gap in its vicinity. The related variation of $\u03c1$ with $1/B$ may be connected with the low-frequency quantum oscillations in lightly doped cuprates. For all considered repulsions, $\u03c1$ has gaps near transfer frequencies of the Hubbard atom, $-\u03bc$ and $U-\u03bc$, with $\u03bc$ the chemical potential. In the heavily underdoped case $\u03bc&lt;0$, Landau subbands are grouped into the lower and upper Hubbard subbands for moderate and large repulsions. The intensity of the upper Hubbard subband decreases with approaching the Fermi level to the lower edge of the spectrum and finally vanishes."}}